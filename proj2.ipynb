{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2\n",
    "### Data science\n",
    "- Abner Gardia 21285\n",
    "- Esteban Donis 21610\n",
    "- Daniel Gomez 21429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project 2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pycountry\n",
    "import names\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inciso 2\n",
    "Analice el problema planteado y los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  \n",
       "0                Adequate  \n",
       "1                Adequate  \n",
       "2                Adequate  \n",
       "3                Adequate  \n",
       "4                Adequate  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36765</td>\n",
       "      <td>36765</td>\n",
       "      <td>36765</td>\n",
       "      <td>36765</td>\n",
       "      <td>36765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36765</td>\n",
       "      <td>4191</td>\n",
       "      <td>36691</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>91B1F82B2CF1</td>\n",
       "      <td>Summer projects should be student-designed</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>12105</td>\n",
       "      <td>20977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        discourse_id      essay_id  \\\n",
       "count          36765         36765   \n",
       "unique         36765          4191   \n",
       "top     0013cc385424  91B1F82B2CF1   \n",
       "freq               1            23   \n",
       "\n",
       "                                     discourse_text discourse_type  \\\n",
       "count                                         36765          36765   \n",
       "unique                                        36691              7   \n",
       "top     Summer projects should be student-designed        Evidence   \n",
       "freq                                             14          12105   \n",
       "\n",
       "       discourse_effectiveness  \n",
       "count                    36765  \n",
       "unique                       3  \n",
       "top                   Adequate  \n",
       "freq                     20977  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36765 entries, 0 to 36764\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   discourse_id             36765 non-null  object\n",
      " 1   essay_id                 36765 non-null  object\n",
      " 2   discourse_text           36765 non-null  object\n",
      " 3   discourse_type           36765 non-null  object\n",
      " 4   discourse_effectiveness  36765 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inciso 3\n",
    "Describa las tareas de limpieza y preprocesamiento que llev√≥ a cabo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios columna discourse_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazar abreviaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"n't\", ' not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"'s\", ' is', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"its\", 'it is', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"'re\", ' are', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"doesn\", 'does not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"don\", 'do not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"didn\", 'did not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"won\", 'will not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"can't\", 'can not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"alot\", 'a lot', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"what's\", 'what is', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"thats\", 'that is', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar cualquier s√≠mbolo que no sea una letra o n√∫mero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"[^a-z0-9A-Z ]\", ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazar palabras como dont, isnt, etc. Que no est√©n escritas con apostrofes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"dont\", 'do not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"isnt\", 'is not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"wont\", 'will not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"werent\", 'were not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"hasnt\", 'has not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"havent\", 'have not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"shouldnt\", 'should not', regex=True)\n",
    "train['discourse_text'] = train['discourse_text'].str.replace(r\"couldnt\", 'could not', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformar todas las palabras a min√∫sculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['discourse_text'] = train['discourse_text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenci√≥n paises para comparar en correcci√≥n de errores ortogr√°ficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aruba', 'afghanistan', 'angola', 'anguilla', '√•land islands', 'albania', 'andorra', 'united arab emirates', 'argentina', 'armenia', 'american samoa', 'antarctica', 'french southern territories', 'antigua and barbuda', 'australia', 'austria', 'azerbaijan', 'burundi', 'belgium', 'benin', 'bonaire, sint eustatius and saba', 'burkina faso', 'bangladesh', 'bulgaria', 'bahrain', 'bahamas', 'bosnia and herzegovina', 'saint barth√©lemy', 'belarus', 'belize', 'bermuda', 'bolivia, plurinational state of', 'brazil', 'barbados', 'brunei darussalam', 'bhutan', 'bouvet island', 'botswana', 'central african republic', 'canada', 'cocos (keeling) islands', 'switzerland', 'chile', 'china', \"c√¥te d'ivoire\", 'cameroon', 'congo, the democratic republic of the', 'congo', 'cook islands', 'colombia', 'comoros', 'cabo verde', 'costa rica', 'cuba', 'cura√ßao', 'christmas island', 'cayman islands', 'cyprus', 'czechia', 'germany', 'djibouti', 'dominica', 'denmark', 'dominican republic', 'algeria', 'ecuador', 'egypt', 'eritrea', 'western sahara', 'spain', 'estonia', 'ethiopia', 'finland', 'fiji', 'falkland islands (malvinas)', 'france', 'faroe islands', 'micronesia, federated states of', 'gabon', 'united kingdom', 'georgia', 'guernsey', 'ghana', 'gibraltar', 'guinea', 'guadeloupe', 'gambia', 'guinea-bissau', 'equatorial guinea', 'greece', 'grenada', 'greenland', 'guatemala', 'french guiana', 'guam', 'guyana', 'hong kong', 'heard island and mcdonald islands', 'honduras', 'croatia', 'haiti', 'hungary', 'indonesia', 'isle of man', 'india', 'british indian ocean territory', 'ireland', 'iran, islamic republic of', 'iraq', 'iceland', 'israel', 'italy', 'jamaica', 'jersey', 'jordan', 'japan', 'kazakhstan', 'kenya', 'kyrgyzstan', 'cambodia', 'kiribati', 'saint kitts and nevis', 'korea, republic of', 'kuwait', \"lao people's democratic republic\", 'lebanon', 'liberia', 'libya', 'saint lucia', 'liechtenstein', 'sri lanka', 'lesotho', 'lithuania', 'luxembourg', 'latvia', 'macao', 'saint martin (french part)', 'morocco', 'monaco', 'moldova, republic of', 'madagascar', 'maldives', 'mexico', 'marshall islands', 'north macedonia', 'mali', 'malta', 'myanmar', 'montenegro', 'mongolia', 'northern mariana islands', 'mozambique', 'mauritania', 'montserrat', 'martinique', 'mauritius', 'malawi', 'malaysia', 'mayotte', 'namibia', 'new caledonia', 'niger', 'norfolk island', 'nigeria', 'nicaragua', 'niue', 'netherlands', 'norway', 'nepal', 'nauru', 'new zealand', 'oman', 'pakistan', 'panama', 'pitcairn', 'peru', 'philippines', 'palau', 'papua new guinea', 'poland', 'puerto rico', \"korea, democratic people's republic of\", 'portugal', 'paraguay', 'palestine, state of', 'french polynesia', 'qatar', 'r√©union', 'romania', 'russian federation', 'rwanda', 'saudi arabia', 'sudan', 'senegal', 'singapore', 'south georgia and the south sandwich islands', 'saint helena, ascension and tristan da cunha', 'svalbard and jan mayen', 'solomon islands', 'sierra leone', 'el salvador', 'san marino', 'somalia', 'saint pierre and miquelon', 'serbia', 'south sudan', 'sao tome and principe', 'suriname', 'slovakia', 'slovenia', 'sweden', 'eswatini', 'sint maarten (dutch part)', 'seychelles', 'syrian arab republic', 'turks and caicos islands', 'chad', 'togo', 'thailand', 'tajikistan', 'tokelau', 'turkmenistan', 'timor-leste', 'tonga', 'trinidad and tobago', 'tunisia', 't√ºrkiye', 'tuvalu', 'taiwan, province of china', 'tanzania, united republic of', 'uganda', 'ukraine', 'united states minor outlying islands', 'uruguay', 'united states', 'uzbekistan', 'holy see (vatican city state)', 'saint vincent and the grenadines', 'venezuela, bolivarian republic of', 'virgin islands, british', 'virgin islands, u.s.', 'viet nam', 'vanuatu', 'wallis and futuna', 'samoa', 'yemen', 'south africa', 'zambia', 'zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "country_names = [country.name.lower() for country in pycountry.countries]\n",
    "\n",
    "print(country_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenci√≥n nombres para comparar en correcci√≥n de errores ortogr√°ficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "namesToCompare = {names.get_first_name().lower() for _ in range(1000)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras aleatorias que debe saltarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsToAvoid = ['bogota', 'americans', 'american', 'leonardo', 'vinci', 'paris', 'europe', 'facs', 'huag', 'beckman', 'venus', 'bugatti', 'nasa', 'beijing', 'colombian', 'colombians', 'mr', 'mrs', 'amd', 'columbian', 'arturo', 'obama', 'venice', 'mona', 'pc', 'andrew', 'april', 'youtube', 'twitter', 'eckman', 'ufo', 'apps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrector de errores de escritura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "def wordCorrection(text):\n",
    "    words = text.split()\n",
    "    misspelled = spell.unknown(words)\n",
    "\n",
    "    for word in misspelled:\n",
    "        if spell.correction(word) is None:\n",
    "            continue\n",
    "        if word in wordsToAvoid:\n",
    "            continue\n",
    "        print(word, spell.correction(word))\n",
    "        text = text.replace(word, spell.correction(word))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['discourse_text'] = train['discourse_text'].apply(wordCorrection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar stop words del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsEnglish = set(stopwords.words('english'))\n",
    "\n",
    "def deleteStopWords(text):\n",
    "    words = text.split()\n",
    "\n",
    "    processed_words = [word for word in words if word not in stopWordsEnglish]\n",
    "\n",
    "    return ' '.join(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['discourse_text'] = train['discourse_text'].apply(deleteStopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios columna discourse_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['discourse_type'] = train['discourse_type'].str.lower()\n",
    "train['discourse_type'] = train['discourse_type'].str.replace(r\"[^a-z0-9 ]\", ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios columna discourse_effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['discourse_effectiveness'] = train['discourse_effectiveness'].str.lower()\n",
    "train['discourse_effectiveness'] = train['discourse_effectiveness'].str.replace(r\"[^a-z0-9 ]\", ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    return text.strip()\n",
    "\n",
    "train['discourse_text'] = train['discourse_text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('result/data_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
